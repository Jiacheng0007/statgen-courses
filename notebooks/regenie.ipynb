{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7609b533-c427-42c4-802c-5f20e63eec73",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# LMM/GLMM analyses for UK Biobank data\n",
    "\n",
    "This notebook implements pipelines for analyzing binary and quantitative traits association using REGENIE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cd631-2e60-458c-bb6b-a77954931548",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run LMM.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8ce2a-7582-4de4-a1b8-0f979ecda13c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path('.')\n",
    "# Genotype files in plink binary this is used for computing the GRM\n",
    "parameter: bfile = path\n",
    "# Path to bgen or bed files \n",
    "parameter: genoFile = paths('.')\n",
    "# Phenotype file for quantitative trait (BMI)\n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column)\n",
    "parameter: phenoCol = list\n",
    "# Covariate file path. Will use phenoFile if empty\n",
    "parameter: covarFile = path('.')\n",
    "# Summary statisticss format file path used for unifying output column names. Will not unify names if empty\n",
    "parameter: formatFile = path('.')\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2\n",
    "# Minimum MAF to be used\n",
    "parameter: bgenMinMAF = 0.001\n",
    "# Mimimum info score to be used\n",
    "parameter: bgenMinINFO = 0.8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# The container with the lmm software. Can be either a dockerhub image or a singularity `sif` file.\n",
    "# Default is set to using dockerhub image\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:2.8'\n",
    "parameter: container_marp = 'gaow/marp'\n",
    "if not covarFile.is_file():\n",
    "    covarFile = phenoFile\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f131b3c-cb73-4d9d-ae62-63e035a7ede0",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### REGENIE example command\n",
    "On a minimal working example (MWE) dataset,\n",
    "\n",
    "```\n",
    "sos run LMM.ipynb regenie \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes21_22.bed \\\n",
    "    --maf-filter 0.001 \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --genoFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --phenoFile data/phenotypes.txt \\\n",
    "    --formatFile data/regenie_template.yml \\\n",
    "    --phenoCol ASTHMA T2D\\\n",
    "    --covarCol SEX \\\n",
    "    --qCovarCol AGE \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 4 \\\n",
    "    --bgenMinMAF 0.05 \\\n",
    "    --bgenMinINFO 0.8 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f85c5-8c1a-4688-b61b-102ee15cc550",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select the SNPs and samples to be used based on maf, geno, hwe and mind options\n",
    "[regenie_qc]\n",
    "parameter: maf_filter = 0.0\n",
    "parameter: geno_filter = 0.0\n",
    "parameter: hwe_filter = 0.0\n",
    "parameter: mind_filter = 0.0\n",
    "input: bfile\n",
    "output: f'{cwd}/cache/{bfile:bn}.qc_pass.id', f'{cwd}/cache/{bfile:bn}.qc_pass.snplist' \n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout' \n",
    "    plink2 \\\n",
    "      --bfile ${bfile:n} --mac 1 \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --write-snplist --write-samples --no-id-header \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output[0]:n} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1622c-a77b-45c1-8aee-a750c8e00f4f",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 1. Fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae2266-3174-4abb-a68d-a851d9423815",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 1: fitting the null\n",
    "[regenie_1,regenie_burden_1]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Path to temporarily store block predictions\n",
    "parameter: lowmem_dir = cwd\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# extract and prepare phenotype & covariate files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat = pd.read_csv(phenoFile, header=0, delim_whitespace=True, dtype=str)\n",
    "dat = dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "if len(phenoCol) > 0:    \n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", sep='\\t', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, delim_whitespace=True, dtype=str)\n",
    "if len(covarCol) > 0 or len(qCovarCol) > 0:\n",
    "    dat = dat.dropna(subset=covarCol)\n",
    "    dat = dat.dropna(subset=qCovarCol)\n",
    "    dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "    dat1 = pd.DataFrame(dat, columns = ['FID','IID'] + covarCol)\n",
    "    #dat1 = dat1.astype(int)\n",
    "    dat2 = pd.DataFrame(dat, columns = ['IID'] + qCovarCol)\n",
    "    merged_left = pd.merge(left=dat1, right=dat2, how='left', left_on='IID', right_on='IID')\n",
    "    merged_left.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_covar\", sep=' ', index=False)\n",
    "depends: f'{cwd}/cache/{bfile:bn}.qc_pass.snplist', f'{cwd}/cache/{bfile:bn}.qc_pass.id'\n",
    "input: geno = bfile, pheno = f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", covar = f\"{cwd}/{phenoFile:bn}.regenie_covar\", qc = output_from(\"regenie_qc\")\n",
    "output: f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', volumes = [f\"{lowmem_dir:a}:{lowmem_dir:a}\"]\n",
    "    regenie \\\n",
    "      --step 1 \\\n",
    "      --bed ${_input[\"geno\"]:n} \\\n",
    "      --phenoFile ${_input[\"pheno\"]} \\\n",
    "      --covarFile ${_input[\"covar\"]} \\\n",
    "      --keep ${_input[\"qc\"][0]} \\\n",
    "      --extract ${_input[\"qc\"][1]} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --lowmem --lowmem-prefix ${lowmem_dir:a}/${_output:bn} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:nn}.regenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda79cc7-9f19-4656-a778-d6dedd3ced22",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 2: association analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56065062-ca5c-4847-98d5-4204b19e9146",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 2: association analysis\n",
    "[regenie_2]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "parameter: trait = 'bt'\n",
    "input: genoFile, group_by = 1, group_with = dict(info=[(path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(genoFile))\n",
    "input_options = f\"--bgen {_input} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bed {_input:n}\"\n",
    "output: [f'{cwd}/cache/{_input:bn}_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:container=container_lmm, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout', volumes = [f\"{cwd:a}:{cwd:a}\"]\n",
    "    set -e\n",
    "    regenie \\\n",
    "     --step 2 \\\n",
    "     ${input_options} \\\n",
    "     --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "     --covarFile ${cwd}/${covarFile:bn}.regenie_covar \\\n",
    "     --phenoColList ${','.join(phenoCol)} \\\n",
    "     ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "     --firth 0.01 --approx \\\n",
    "     --pred ${_input.info} \\\n",
    "     --bsize ${bsize} \\\n",
    "     --minMAC ${minMAC} \\\n",
    "     --minINFO ${bgenMinINFO}\\\n",
    "     --threads ${numThreads} \\\n",
    "     --out ${cwd}/cache/${_input:bn} && \\\n",
    "     gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174108f2-b3f4-48d0-b910-4a54011e30b6",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Regenie burden test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57563d50-c8d0-4ed6-ba67-1d5865b88a47",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run regenie for burden tests\n",
    "[regenie_burden_2]\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Annotation file format: variantID, gene and functional annotation (space/tab delimited)\n",
    "parameter: anno_file = path\n",
    "# This file lists variants within each set/gene to use when building masks. Format: set/gene name, chromosome, physical pos set/gene, then by a comma-separated list of variants included in the set/gene.\n",
    "parameter: set_list = path\n",
    "# Select specific genes/sets to test\n",
    "parameter: keep_gene = path(\".\")\n",
    "# Allele frequency file. format: variantId, alternative allele frequency\n",
    "parameter: aaf_file = path(\".\")\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.05]\n",
    "# The way in which the alternative alleles are counted\n",
    "parameter: build_mask = 'max'\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "input: genoFile, group_by = 1, group_with = dict(info=[(path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(genoFile))\n",
    "input_options = f\"--bgen {_input} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bed {_input:n}\"\n",
    "output: [f'{cwd}/cache/{_input:bn}_burden_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:container=container_lmm, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout', volumes = [f\"{cwd:a}:{cwd:a}\"]\n",
    "    set -e\n",
    "    regenie \\\n",
    "      --step 2 \\\n",
    "      ${input_options} \\\n",
    "      --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "      --covarFile ${cwd}/${covarFile:bn}.regenie_covar \\\n",
    "      --phenoColList ${','.join(phenoCol)} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      ${(\"--extract-sets \" + str(keep_gene)) if keep_gene.is_file() else \"\"} \\\n",
    "      --firth --approx \\\n",
    "      --pred ${_input.info} \\\n",
    "      --set-list ${set_list} \\\n",
    "      --anno-file ${anno_file} \\\n",
    "      --mask-def ${mask_file} \\\n",
    "      --aaf-bins ${\",\".join([str(x) for x in aaf_bins])}\\\n",
    "      ${('--build-mask ' + build_mask) if build_mask in ['max','sum','comphet'] else ''} \\\n",
    "      ${('--aaf-file ' + str(aaf_file)) if aaf_file.is_file() else \"\"}\\\n",
    "      --singleton-carrier \\\n",
    "      --write-mask-snplist \\\n",
    "      --write-mask \\\n",
    "      --minMAC ${minMAC} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --check-burden-files \\\n",
    "      --out  ${cwd}/cache/${_input:bn}_burden && \\\n",
    "      gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07a8b2-84f3-4996-8b56-a1345e3cf1a1",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[regenie_burden_3]\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.05]\n",
    "aaf_bins = ['singleton'] + aaf_bins\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "output: [f'{cwd}/cache/{_input:bn}_'+ str(phenoCol[i]) + \"_\" + str(masks[j]) + \".\" + str(aaf_bins[k]) + '.regenie.gz' for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))] \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: container=container_lmm, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout', volumes = [f\"{cwd:a}:{cwd:a}\"]\n",
    "    import pandas as pd \n",
    "\n",
    "    if len(${phenoCol}) == 1:\n",
    "        _input = [\"${_input}\"]\n",
    "    else:\n",
    "        _input = [f'{i}' for i in \"${_input}\".split(\" \")]\n",
    "\n",
    "    allele_combos = [str(m) + \".\" + str(a) for m in ${masks} for a in ${aaf_bins}]\n",
    "    for i, phen in enumerate(${phenoCol}):\n",
    "        f = pd.read_csv(_input[i], sep=\" \", skiprows=1)\n",
    "        dfs = dict()\n",
    "        for each in allele_combos:\n",
    "            dfs[each] = f[f[\"ALLELE1\"] == each]\n",
    "\n",
    "        for df in dfs.keys():\n",
    "            dfs[df].to_csv(f'${cwd}/cache/${_input:bn}_{phen}'+ \"_\" + df + '.regenie.gz', sep=\" \", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5b7ef-1cfb-4d67-905a-7b9530c11035",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66081803-424e-4d78-9861-5c6d63f1b73f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge results and log files\n",
    "[regenie_3, regenie_burden_4]\n",
    "parameter:reverse_log_p = False\n",
    "depends: formatFile\n",
    "input: group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "output: f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz',\n",
    "        f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '1h', mem = '36G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: container=container_lmm, expand ='${ }'\n",
    "    import gzip\n",
    "    import pandas as pd\n",
    "    if ${formatFile.is_file()}:\n",
    "        output = '${_output[0]:n}' + '_original_columns' + '${_output[0]:x}'\n",
    "    else:\n",
    "        output = '${_output[0]}'\n",
    "   \n",
    "\n",
    "    data = pd.concat([pd.read_csv(f, compression='gzip', header=0, delim_whitespace=True, quotechar='\"', comment='#') for f in [${_input:r,}]], ignore_index=True)\n",
    "    data.to_csv(output, compression='gzip', sep='\\t', header = True, index = False)\n",
    "    # unify output format\n",
    "    if ${formatFile.is_file()} or ${reverse_log_p}:\n",
    "        sumstats = pd.read_csv(output, compression='gzip', header=0, delim_whitespace=True, quotechar='\"')  \n",
    "        if ${formatFile.is_file()}:\n",
    "            import yaml\n",
    "            config = yaml.safe_load(open(${formatFile:r}, 'r'))\n",
    "        try:\n",
    "            sumstats = sumstats.loc[:,list(config.values())]\n",
    "        except:\n",
    "            raise ValueError(f'According to ${formatFile}, input summary statistics should have the following columns: {list(config.values())}.')\n",
    "        sumstats.columns = list(config.keys())\n",
    "        if ${reverse_log_p}:\n",
    "            sumstats['P'] = sumstats['P'].apply(lambda row: 10**-row)\n",
    "        sumstats.to_csv(${_output[0]:r}, compression='gzip', sep='\\t', header = True, index = False)        \n",
    "\n",
    "bash: container=container_lmm, expand=\"$( )\"\n",
    "    # count result SNPs\n",
    "    for f in $(_input); do echo \"$f: `zcat $f | wc -l`\"; done > $(_output[1])\n",
    "    # merge stderr and stdout files\n",
    "    for f in $(_input); do \n",
    "        for ext in stderr stdout log; do\n",
    "            echo \"$f $ext:\"\n",
    "            cat ${f%.gz}.$ext 2>/dev/null || true\n",
    "            rm -f ${f%.gz}.$ext \n",
    "        done\n",
    "    done > $(_output[0]:n).log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ecf35-1c75-439f-9e28-cadd8b54aec1",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Separate the mask and MAF bins and remove the single variant genes\n",
    "[regenie_burden_5]\n",
    "# Top k genes to be annotated\n",
    "parameter: k = 10\n",
    "# P value limitation for annotation\n",
    "parameter: plim = 2.5E-6\n",
    "# A given list of gene for annotation\n",
    "parameter: genelist = \"\"\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins = [0.05]\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "bins=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))]\n",
    "input: [f'{cwd}/{phenoFile:bn}_' + str(phenoCol[i]) +f'.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz' for i in range(len(phenoCol))]+[f'{cwd}/{phenoFile:bn}_' + str(phenoCol[i]) +f'.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt' for i in range(len(phenoCol))],group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "output: [f'{cwd}/{phenoFile:bn}_' + bins[n] + '.snp_stats.gz' for n in range(len(bins))]+[f'{cwd}/{phenoFile:bn}_' + bins[n] + '.snp_counts.txt' for n in range(len(bins))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_input[0]:bn}'    \n",
    "python: container=container_lmm, expand = \"${ }\", stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    import gzip\n",
    "    import pandas as pd\n",
    "    data=pd.read_csv(${_input[0]:r}, compression='gzip', header=0, delim_whitespace=True, quotechar='\"', comment='#')\n",
    "    binlist=pd.unique(data.ALT)\n",
    "\n",
    "    for bin in binlist:\n",
    "        # Separate regenie resulta into mask and MAF bins\n",
    "        data[data['ALT']==bin].to_csv(\"${_input[0]:nn}.\"+bin+'.snp_stats.gz', compression='gzip', sep='\\t', header = True, index = False)\n",
    "        \n",
    "    \n",
    "    count=pd.read_csv(${_input[1]:r}, header=None, delim_whitespace=True)\n",
    "    for bin in binlist:\n",
    "        count[count[0].str.contains(bin)].to_csv(\"${_input[0]:nn}.\"+bin+'.snp_counts.txt', sep='\\t', header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd85d5-4dea-4b09-bce5-b15d28d976ad",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Manhattan and QQ plots\n",
    "\n",
    "Before running the pipeline make sure you have installed the necessary packages. We use the `qqman` package from R: https://www.r-graph-gallery.com/101_Manhattan_plot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833fad63-1123-4e65-b101-d6f361407bf1",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[regenie_4]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for SNP\n",
    "parameter: snp = 'SNP'\n",
    "# Plot only on p-values smaller than this\n",
    "parameter: p_filter = '0.05'\n",
    "# Higlight SNPs with P-values lower than this\n",
    "parameter: sigp = 5e-08\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "sep = '\\n\\n---\\n'\n",
    "depends: phenoFile\n",
    "input: group_by = 2, group_with = 'phenoCol'\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_output[0]:bn}'    \n",
    "bash: container=container_lmm, expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[2]}\n",
    "    \n",
    "R: container=container_lmm, expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    pheno = read.table(${phenoFile:r}, header=T, sep = \"\")$${_phenoCol}\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write('# ${_phenoCol} result summary\\n## Phenotype summary:\\n```', ${_output[2]:r}, append = T)\n",
    "    write.table(out, ${_output[2]:r}, append = T)\n",
    "    write(\"```\", ${_output[2]:r}, append = T)\n",
    "\n",
    "R: container=container_lmm, expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), sep='\\t', header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1), na.rm=TRUE)/qchisq(0.5,1)\n",
    "    ifelse((${ylim} == 0 && min(data$${pval}, na.rm=TRUE)!=0), ylim <- abs(floor(log10(min(data$${pval}, na.rm=TRUE)))), ylim <- abs(floor(log10(2.225074e-308))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = 'Manhattan plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"), chrlabs = as.character(c(1:22)))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = 'QQ Plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[2]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"variants analyzed.${sep}\"), ${_output[2]:r}, append=T)\n",
    "     \n",
    "bash: container=container_lmm, expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_phenoCol}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Manhattan plot for {_phenoCol}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[2]}\n",
    "  ls {_input[0]:nn}.* | grep -vP 'stderr|stdout'>> {_output[2]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b19cb22-b362-4ad1-b230-21cde1a9f7fd",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[regenie_burden_6]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for genes\n",
    "parameter: snp = 'SNP'\n",
    "# Plot only on p-values smaller than this\n",
    "parameter: p_filter = '0.05'\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.05]\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation_type\n",
    "parameter: mask_file = path(\".\")\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "bins=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))]\n",
    "sep = '\\n\\n---\\n'\n",
    "depends: phenoFile\n",
    "input: [f'{cwd}/{phenoFile:bn}_' + bins[n] + '.snp_stats.gz' for n in range(len(bins))], group_by=1\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_output[0]:bn}'   \n",
    "bash: container=container_lmm, expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[2]}\n",
    "    \n",
    "R: container=container_lmm, expand='${ }', stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    tmp=unlist(strsplit(${_input[0]:r},\"${cwd}/${phenoFile:bn}_\"))[2]\n",
    "    bins=unlist(strsplit(tmp,\".snp_stats.gz\"))[1]\n",
    "    phenoCol=unlist(strsplit(bins,\"\\\\.\"))[1]\n",
    "    pheno = read.table(${phenoFile:r}, header=T, sep = \"\\t\")[phenoCol]\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write(paste0('# ',bins,' result summary\\n## Phenotype summary:\\n```'), ${_output[2]:r}, append = T)\n",
    "    write.table(out, ${_output[2]:r}, append = T)\n",
    "    write(\"```\", ${_output[2]:r}, append = T)\n",
    "\n",
    "R: container=container_lmm, expand='${ }', stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    tmp=unlist(strsplit(${_input[0]:r},\"${cwd}/${phenoFile:bn}_\"))[2]\n",
    "    bins=unlist(strsplit(tmp,\".snp_stats.gz\"))[1]\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), sep='\\t', header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1), na.rm=TRUE)/qchisq(0.5,1)\n",
    "    ifelse((${ylim} == 0 && min(data$${pval}, na.rm=TRUE)!=0), ylim <- abs(floor(log10(min(data$${pval}, na.rm=TRUE)))), ylim <- abs(floor(log10(2.225074e-308))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = paste0('Manhattan plot for ',bins), ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"))  #, chrlabs = as.character(c(1:22))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = paste0('QQ plot for ',bins), xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[2]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"genes analyzed.${sep}\"), ${_output[2]:r}, append=T)\n",
    "    \n",
    "bash: container=container_lmm, expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_input[0]:bnnn}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Manhattan plot for {_input[0]:bnnn}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[2]}\n",
    "  ls {_input[0]:nnn}.* | grep -vP 'stderr|stdout'>> {_output[2]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[2]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
